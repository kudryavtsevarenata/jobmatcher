# JobMatcher
Выполнили:
- Кудрявцева Рената (РИС-25-1м)


# Обоснование выбора Ollama как платформы для запуска LLM
1. Простота развертывания и администрирования (в рамках эксперимента развертывание рабочей среды заняло менее 15 минут)
2. Экосистема и поддержка сообщества (Ollama поддерживает множество моделей в своем репозитории)
3. Безопасность и приватность данных (поскольку Ollama работает локально, все данные обработки резюме никуда не сливаются)
4. Интеграция со знакомым стеком технологий (Ollama интегрируется с Python-экосистемой через прямые HTTP-запросы и официальный Python-пакет)


# Обоснование выбора LLM

## Критерии выбора модели
1. Хорошее понимание русского языка
2. Способность к структурированному выводу (генерация JSON с результатами анализа)
3. Эффективность ресурсов (возможность запуска на доступном оборудовании)
4. Бесплатное использование


Три модели были выбраны для сравнения:

1. Qwen2.5:7b
2. Llama 3.2:3b
3. Gemma 2:9b

### Тест 1: Понимание русскоязычных технических текстов

Для тестирования использован пример резюме Python-разработчика. Задача модели заключалась в извлечении навыков и опыта работы.

**Пример промпта:**
```
Извлеки технические навыки и опыт из резюме:
"Senior Python разработчик с 5 годами опыта. 
Технологии: Python, FastAPI, PostgreSQL, Docker, AWS.
Последние 2 года работал над high-load системой обработки платежей."
```

**Результаты:**
Все модели извлекли все 5 технологий, корректно определили опыт работы и правильно идентифицировала специализацию.

### Тест 2: Генерация структурированного JSON

**Пример задания:**
```
Проанализируй соответствие кандидата и вакансии. Верни JSON:
{
  "match_percent": число от 0 до 100,
  "matched_skills": ["список"],
  "missing_skills": ["список"],
  "reason": "одно предложение"
}
```

- *Qwen2.5:7b* в большинстве случаев возвращала валидный JSON, строго следуя заданной схеме, с конкретными цифрами и списками навыков.
- *Llama 3.2:3b* часто пропускала обязательные поля или нарушала структуру
- *Gemma 2:9b* в большинстве случаев возвращала валидный JSON, но часто использовала слишком общие формулировки в поле "reason".

### Тест 3: Производительность и ресурсы

На оборудовании с 16GB RAM и без выделенной GPU, замеры по анализу одного резюме:

```
Модель               Время (сек)  Память пик (MB) Память ср (MB)
----------------------------------------------------------------------
llama3.2:3b          14.09        7398.2          6338.9
gemma2:9b            34.04        7435.8          5603.9
qwen2.5:7b           26.42        6783.9          4267.5
```

Хотя Llama 3.2:3b быстрее, ее качество анализа существенно ниже. Gemma 2:9b требует больше ресурсов и времени
при сопоставимом качестве с Qwen2.5.

## Вывод

Для работы выбрана Qwen2.5:7b.
